{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_A3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "SVdfX-AM8e-B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XV7fJTkX82kc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = '/content/drive/My Drive/A3/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GiiMI-Ft9FmF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eg9bxxjLDl2U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import random\n",
        "from itertools import cycle\n",
        "from sklearn.externals import joblib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8pHDwfKy9Re1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST(path, train=True, download=True,\n",
        "#                                            transform=torchvision.transforms.Compose([\n",
        "#                                                      torchvision.transforms.ToTensor(),\n",
        "#                                                      torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
        "#                                                      ])), batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YRkhMJUR-4Ec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# test_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST(path, train=False, download=True,\n",
        "#                                            transform=torchvision.transforms.Compose([\n",
        "#                                                      torchvision.transforms.ToTensor(),\n",
        "#                                                      torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
        "#                                                      ])), batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BO-u2t0YAz1B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "outputId": "07fcba8a-01e7-4f74-e874-a84f1c385a5c"
      },
      "cell_type": "code",
      "source": [
        "encoder = Encoder()\n",
        "encoder = encoder.cuda()\n",
        "decoder = Decoder()\n",
        "decode = decoder.cuda()\n",
        "adv = Discriminator()\n",
        "adv = adv.cuda()\n",
        "\n",
        "train_loader = MNIST_Paired()\n",
        "\n",
        "encoder.apply(weights_init)\n",
        "decoder.apply(weights_init)\n",
        "\n",
        "z = torch.FloatTensor(64, 16)\n",
        "z = z.cuda()\n",
        "\n",
        "adversarial_loss = torch.nn.BCELoss()\n",
        "adversarial_loss.cuda()\n",
        "\n",
        "auto_encoder_optimizer = optim.Adam(list(encoder.parameters())+list(decoder.parameters()), lr=1e-3, betas=(0.9, 0.999))\n",
        "adversary_optimizer = optim.Adam(list(adv.parameters()), lr=2e-3, betas=(0.5, 0.9))\n",
        "\n",
        "auto_encoder_scheduler = optim.lr_scheduler.StepLR(auto_encoder_optimizer, step_size=20, gamma=0.1)\n",
        "adversary_scheduler = optim.lr_scheduler.StepLR(adversary_optimizer, step_size=20, gamma=0.1)\n",
        "\n",
        "loader = cycle(torch.utils.data.DataLoader(train_loader, batch_size=64, shuffle=True, num_workers=0, drop_last=True))\n",
        "\n",
        "for epoch in range(100):\n",
        "    loss = 0\n",
        "    loss_plot = []\n",
        "    auto_encoder_scheduler.step()\n",
        "    adversary_scheduler.step()\n",
        "    tempList = []\n",
        "    for iteration in range(int(len(train_loader)/64)):\n",
        "        #AE training\n",
        "        auto_encoder_optimizer.zero_grad()\n",
        "        \n",
        "        #Sample a triplet of samples with two data points having same label, third one can be random\n",
        "        x_1, x_2, labels = next(loader)\n",
        "        x_3, _, id_3 = next(loader)\n",
        "        #Convert to cuda\n",
        "        x_1 = x_1.cuda()\n",
        "        x_2 = x_2.cuda()\n",
        "        x_3 = x_3.cuda()\n",
        "        id_3 = id_3.cuda()\n",
        "        #Computing the codes by passing through encoder\n",
        "        z_mean_1, z_var_1, s_1 = encoder(Variable(x_1))\n",
        "        z_mean_2, z_var_2, s_2 = encoder(Variable(x_2))\n",
        "        z_mean_3, z_var_3, s_3 = encoder(Variable(x_3))\n",
        "        #Sampling style_latent_variables using reparameterisation trick\n",
        "        z_1 = reparameterize(True, z_mean_1, z_var_1)\n",
        "        z_2 = reparameterize(True, z_mean_2, z_var_2)\n",
        "        z_3 = reparameterize(True, z_mean_3, z_var_3)\n",
        "        #Reconstructing the image by passing through the decoder\n",
        "        reconstructed_X11 = decoder(z_1, s_1)\n",
        "        reconstructed_X12 = decoder(z_1, s_2)\n",
        "        #Computing the reconstruction loss and updating the gradient\n",
        "        reconstruction_loss_11 = mse_loss(reconstructed_X11, Variable(x_1))\n",
        "        reconstruction_loss_12 = mse_loss(reconstructed_X12, Variable(x_1))\n",
        "        reconstruction_loss = (reconstruction_loss_11 + reconstruction_loss_12)/2. \n",
        "        #loss += reconstruction_loss.data.storage().tolist()[0]\n",
        "        reconstruction_loss.backward(retain_graph=True)\n",
        "        #Compute the generation on random data point i.e., x_3 and update the gradients based on adversarial loss\n",
        "        reconstructed_X13 = decoder(z_1, s_3)\n",
        "        adv_loss_1 = (-0.5*torch.sum(1+z_var_1-z_mean_1.pow(2)-z_var_1.exp()))/(64*1*28*28)\n",
        "        z.normal_(0.,1.)\n",
        "        reconstructed_X_3 = decoder(z, s_3)\n",
        "        adv_loss_2 = (-0.5*torch.sum(1+torch.var(z)-torch.mean(z).pow(2)-torch.var(z).exp()))/(64*1*28*28)\n",
        "        adv_loss = (adv_loss_1+adv_loss_2)/2.\n",
        "        adv_loss.backward(retain_graph=True)\n",
        "        auto_encoder_optimizer.step()\n",
        "        #Adversary training\n",
        "        adversary_optimizer.zero_grad()\n",
        "        x_1, _, id_1 = next(loader)\n",
        "        x_2, _, id_2 = next(loader)\n",
        "        \n",
        "        x_1 = x_1.cuda()\n",
        "        x_2 = x_2.cuda()\n",
        "        id_1 = id_1.cuda()\n",
        "        id_2 = id_2.cuda()\n",
        "        \n",
        "        z_mean_1, z_var_1, s_1 = encoder(Variable(x_1))\n",
        "        z_mean_2, z_var_2, s_2 = encoder(Variable(x_2))\n",
        "        \n",
        "        z_1 = reparameterize(True, z_mean_1, z_var_1)\n",
        "        z_2 = reparameterize(True, z_mean_2, z_var_2)\n",
        "        \n",
        "        reconstructed_X11 = decoder(z_1, s_1)\n",
        "        reconstructed_X12 = decoder(z_1, s_2)\n",
        "        \n",
        "        adv_loss = (-0.5*torch.sum(1+z_var_1-z_mean_1.pow(2)-z_var_1.exp()))/(64*1*28*28)\n",
        "        \n",
        "        adv_loss.backward(retain_graph=True)\n",
        "        adversary_optimizer.step()\n",
        "        \n",
        "        cnt = 0\n",
        "        if (iteration+1) % 100 == 0:\n",
        "            cnt += 1\n",
        "            print('Epoch\\t'+str(epoch),'Iter\\t'+str(iteration), \n",
        "                  'Loss\\t' + str(reconstruction_loss.data.storage().tolist()[0]))\n",
        "            loss += reconstruction_loss.data.storage().tolist()[0]\n",
        "            loss_plot.append(loss/cnt)\n",
        "        for i in range(len(z_1.cpu().data.numpy().tolist())):\n",
        "                temp = []\n",
        "                temp.append(z_1.cpu().data.numpy().tolist()[i])\n",
        "                temp.append(labels[i].cpu().data.numpy().tolist())\n",
        "                tempList.append(temp) \n",
        "   \n",
        "    if (epoch+1) % 20 == 0 or (epoch + 1) == 100:\n",
        "        temp = []\n",
        "        torch.save(encoder.state_dict(), path + 'encoder.weights')\n",
        "        torch.save(decoder.state_dict(), path + 'decoder.weights')\n",
        "\n",
        "\n",
        "        inputs_1, inputs_2, __ = next(loader)\n",
        "        inputs_3, _, __ = next(loader)\n",
        "        inputs_1, inputs_2, inputs_3 = inputs_1.cuda(), inputs_2.cuda(), inputs_3.cuda()\n",
        "        z_mean_1, z_var_1, s_1 = encoder(Variable(inputs_1))\n",
        "        z_mean_2, z_var_2, s_2 = encoder(Variable(inputs_2))\n",
        "        z_mean_3, z_var_3, s_3 = encoder(Variable(inputs_3))\n",
        "\n",
        "        z_1 = reparameterize(False, z_mean_1, z_var_1)\n",
        "        z_3 = reparameterize(False, z_mean_3, z_var_3)\n",
        "        \n",
        "        reconstructed_X_12 = decoder(z_1, s_2)\n",
        "        reconstructed_X_32 = decoder(z_3, s_2)\n",
        "\n",
        "        image_batch = np.transpose(inputs_1.cpu().numpy(), (0, 2, 3, 1))\n",
        "        image_batch = np.concatenate((image_batch, image_batch, image_batch), axis=3)\n",
        "        imshow_grid(image_batch, name=str(epoch) + '_original', save=True)\n",
        "\n",
        "#         reconstructed_x = np.transpose(reconstructed_X_12.cpu().data.numpy(), (0, 2, 3, 1))\n",
        "#         reconstructed_x = np.concatenate((reconstructed_x, reconstructed_x, reconstructed_x), axis=3)\n",
        "#         imshow_grid(reconstructed_x, name=str(epoch) + '_target', save=True)\n",
        "\n",
        "        style_batch = np.transpose(inputs_3.cpu().numpy(), (0, 2, 3, 1))\n",
        "        style_batch = np.concatenate((style_batch, style_batch, style_batch), axis=3)\n",
        "        imshow_grid(style_batch, name=str(epoch) + '_style', save=True)\n",
        "\n",
        "        reconstructed_style = np.transpose(reconstructed_X_32.cpu().data.numpy(), (0, 2, 3, 1))\n",
        "        reconstructed_style = np.concatenate((reconstructed_style, reconstructed_style, reconstructed_style), axis=3)\n",
        "        imshow_grid(reconstructed_style, name=str(epoch) + '_style_target', save=True)\n",
        "        \n",
        "        \n",
        "        joblib.dump(tempList, path+'tsne.sav')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch\t0 Iter\t99 Loss\t0.6503085494041443\n",
            "Epoch\t0 Iter\t199 Loss\t0.5767725706100464\n",
            "Epoch\t0 Iter\t299 Loss\t0.5525031685829163\n",
            "Epoch\t0 Iter\t399 Loss\t0.5341758728027344\n",
            "Epoch\t0 Iter\t499 Loss\t0.5366477370262146\n",
            "Epoch\t0 Iter\t599 Loss\t0.5277217030525208\n",
            "Epoch\t0 Iter\t699 Loss\t0.5190153121948242\n",
            "Epoch\t0 Iter\t799 Loss\t0.5105174779891968\n",
            "Epoch\t0 Iter\t899 Loss\t0.5038754343986511\n",
            "Epoch\t1 Iter\t99 Loss\t0.5094743967056274\n",
            "Epoch\t1 Iter\t199 Loss\t0.5086038112640381\n",
            "Epoch\t1 Iter\t299 Loss\t0.5139362812042236\n",
            "Epoch\t1 Iter\t399 Loss\t0.5065673589706421\n",
            "Epoch\t1 Iter\t499 Loss\t0.5139414072036743\n",
            "Epoch\t1 Iter\t599 Loss\t0.513563871383667\n",
            "Epoch\t1 Iter\t699 Loss\t0.5038045048713684\n",
            "Epoch\t1 Iter\t799 Loss\t0.5005918741226196\n",
            "Epoch\t1 Iter\t899 Loss\t0.4925180673599243\n",
            "Epoch\t2 Iter\t99 Loss\t0.500091552734375\n",
            "Epoch\t2 Iter\t199 Loss\t0.5027673840522766\n",
            "Epoch\t2 Iter\t299 Loss\t0.5058207511901855\n",
            "Epoch\t2 Iter\t399 Loss\t0.500218391418457\n",
            "Epoch\t2 Iter\t499 Loss\t0.5092052221298218\n",
            "Epoch\t2 Iter\t599 Loss\t0.5079705119132996\n",
            "Epoch\t2 Iter\t699 Loss\t0.4987547993659973\n",
            "Epoch\t2 Iter\t799 Loss\t0.4963473975658417\n",
            "Epoch\t2 Iter\t899 Loss\t0.48865246772766113\n",
            "Epoch\t3 Iter\t99 Loss\t0.49629491567611694\n",
            "Epoch\t3 Iter\t199 Loss\t0.49800798296928406\n",
            "Epoch\t3 Iter\t299 Loss\t0.5030725002288818\n",
            "Epoch\t3 Iter\t399 Loss\t0.49713703989982605\n",
            "Epoch\t3 Iter\t499 Loss\t0.506761908531189\n",
            "Epoch\t3 Iter\t599 Loss\t0.5093778967857361\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-292f9467f9cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                 \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mtempList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ulr6xOBcx6wp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "                        nn.Conv2d(1, 16, kernel_size=5, stride=2, padding=1, bias=True),\n",
        "                        nn.BatchNorm2d(num_features=16, track_running_stats=True),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=1, bias=True),\n",
        "                        nn.BatchNorm2d(num_features=32, track_running_stats=True),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=1, bias=True),\n",
        "                        nn.BatchNorm2d(num_features=64, track_running_stats=True),\n",
        "                        nn.ReLU())\n",
        "        \n",
        "        self.mean = nn.Linear(256,16,bias=True)\n",
        "        self.var = nn.Linear(256,16,bias=True)\n",
        "        self.s = nn.Linear(256,16,bias=True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
        "        z_mean = self.mean(x)\n",
        "        z_var = self.var(x)\n",
        "        s_ = self.s(x)\n",
        "        return z_mean, z_var, s_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JeG0FeEF3IGU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.z_input = nn.Linear(16, 256, bias=True)\n",
        "        self.s_input = nn.Linear(16, 256, bias=True)\n",
        "        self.transposeConv = nn.Sequential(\n",
        "                                nn.ConvTranspose2d(128, 32, kernel_size=4, stride=2, padding=0, bias=True),\n",
        "                                nn.BatchNorm2d(32),\n",
        "                                nn.LeakyReLU(negative_slope=0.2),\n",
        "                                nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=0, bias=True),\n",
        "                                nn.BatchNorm2d(16),\n",
        "                                nn.LeakyReLU(negative_slope=0.2),\n",
        "                                nn.ConvTranspose2d(16, 1, kernel_size=4, stride=2, padding=1, bias=True),\n",
        "                                nn.Sigmoid())\n",
        "    \n",
        "    def forward(self, z_embeddings, s_embeddings):\n",
        "        z_embeddings = F.leaky_relu_(self.z_input(z_embeddings), negative_slope=0.2)\n",
        "        s_embeddings = F.leaky_relu_(self.s_input(s_embeddings), negative_slope=0.2)\n",
        "\n",
        "        x = torch.cat((z_embeddings, s_embeddings), dim=1)\n",
        "        x = x.view(x.size(0), 128, 2, 2)\n",
        "        x = self.transposeConv(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oi5vxDYLMEPQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reparameterize(training, mean, var):\n",
        "    if training:\n",
        "        std = var.mul(0.5).exp_()\n",
        "        eps = Variable(std.data.new(std.size()).normal_())\n",
        "        return eps.mul(std).add_(mean)\n",
        "    else:\n",
        "        return mean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AdK_3lFdZ3TB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mse_loss(x_1, x_2):\n",
        "    return torch.sum((x_1-x_2).pow(2))/x_1.data.nelement()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9uMva2uf7pqG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def imshow_grid(images, shape=[8, 8], name='default', save=False):\n",
        "    fig = plt.figure(1)\n",
        "    grid = ImageGrid(fig, 111, nrows_ncols=shape, axes_pad=0.05)\n",
        "    \n",
        "    size = shape[0] * shape[1]\n",
        "    for i in range(size):\n",
        "        grid[i].axis('off')\n",
        "        grid[i].imshow(images[i])\n",
        "\n",
        "    if save:\n",
        "        plt.savefig(path + str(name) + '.png')\n",
        "        plt.clf()\n",
        "    else:\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b1nsUZUt7hI7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MNIST_Paired():\n",
        "    def __init__(self):\n",
        "        self.mnist = torchvision.datasets.MNIST(root=path, download=True, train=True, transform=torchvision.transforms.Compose([\n",
        "                                                     torchvision.transforms.ToTensor(),\n",
        "                                                     torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                                     ]))\n",
        "                                                                                                          \n",
        "        self.data_dict = {}\n",
        "\n",
        "        for i in range(self.__len__()):\n",
        "            image, label = self.mnist.__getitem__(i)\n",
        "\n",
        "            try:\n",
        "                self.data_dict[label]\n",
        "            except KeyError:\n",
        "                self.data_dict[label] = []\n",
        "            self.data_dict[label].append(image)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.mnist.__len__()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.mnist.__getitem__(index)\n",
        "        return image, random.SystemRandom().choice(self.data_dict[label]), label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yITzbEvvKa-E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = [\n",
        "            nn.Linear(16, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        ]\n",
        "        for idx, module in enumerate(self.main):\n",
        "            self.add_module(str(idx), module)\n",
        "    def forward(self, x):\n",
        "        for layer in self.main:\n",
        "            x = layer(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_51W_MxsLC2a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def weights_init(layer):\n",
        "    if isinstance(layer, nn.Conv2d):\n",
        "        layer.weight.data.normal_(0.0, 0.05)\n",
        "        layer.bias.data.zero_()\n",
        "    elif isinstance(layer, nn.BatchNorm2d):\n",
        "        layer.weight.data.normal_(1.0, 0.02)\n",
        "        layer.bias.data.zero_()\n",
        "    elif isinstance(layer, nn.Linear):\n",
        "        layer.weight.data.normal_(0.0, 0.05)\n",
        "        layer.bias.data.zero_()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9NgFJ5RnCHX_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "78baf13a-ed4d-4ad3-952f-5b19e134af0f"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(range(len(loss_plot), loss_plot))\n",
        "plt.show()\n",
        "         "
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-6f78b69c4a8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_plot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_plot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'list' object cannot be interpreted as an integer"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "5g68YwewNCEN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}